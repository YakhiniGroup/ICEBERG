"""
This Python module is used to count:
1. Reads from fastq file.
2. Reads from bam (generated by bwa) file.
3. Reads from iceberg sites dataframe for single experiment (treatment or control) iceberg sites dataframe.
4. Reads iceberg sites for merged experiments (treatment and control) iceberg sites dataframe.

(for iterate over the file)
"""

import settings

from pathlib import Path
import pandas as pd
import logging
import os
import subprocess
from utils import logs


def count_fastq_reads(files_folder: Path, samples_files: list) -> list:
    """
    Counts the reads in the given fastq files.

    :param files_folder: A path to the directory contains the umi or tag step output files.
    :param samples_files: A list of tuples - (files-key (in args_dict), real-file-name).

    :return: The reads count after classify step
    """
    reads_amount = []
    for sample_file in samples_files:
        try:
            file_path = '{fastq_file_path}'.format(fastq_file_path=files_folder / sample_file)
            file_reads_count = int(subprocess.check_output(['wc', '-l', file_path]).split()[0]) // 4
            reads_amount.append((sample_file, file_reads_count))
        except Exception as e:
            logging.error(f'Failed to count reads in {sample_file} please validate file.', exc_info=False)
            # sys.exit()
            raise e
    return reads_amount


def count_sam_bwa_reads(files_folder: Path, samples_files: list) -> list:
    """
    Counts the reads in the given sam files.

    :param files_folder: A path to the directory contains the files.
    :param samples_files: A list of tuples - (files-key in args_dict, real-file-name).

    :return: The reads count after classify step
    """
    reads_amount = []
    for sample_file in samples_files:
        try:
            file_path = '{sam_file_path}'.format(sam_file_path=files_folder / sample_file)
            file_reads_count = int(subprocess.check_output(['samtools', 'flagstat', file_path]).split()[0])
            reads_amount.append((sample_file, file_reads_count))
        except Exception as e:
            logging.error(f'Failed to count reads in {sample_file} please validate file.', exc_info=False)
            # sys.exit()
            raise e
    return reads_amount


def count_iceberg_csv_reads(files_folder: Path,
                            samples_files: list) -> list:
    """
    Counts the reads in the given icebergs csv files.

    :param files_folder: A path to the directory contains the unite step output files.
    :param samples_files: A list of tuples - (files-key (in args_dict), real-file-name).

    :return: The reads count after classify step
    """
    reads_amount = []
    for sample_file in samples_files:
        try:
            df = pd.read_csv(str(files_folder / sample_file))
            reads_amount.append((sample_file, df.loc[:, 'read count'].map(lambda x: float(x)).sum()))
        except Exception as e:
            logging.error(f'Failed to count reads in {sample_file} please validate file.', exc_info=False)
            # sys.exit()
            raise e
    return reads_amount


def count_icebergs_merged_csv_reads(files_folder: Path, samples_files: list) -> list:
    """
    Calculates the reads count after the classify step.

    :param files_folder: A path to the directory contains the classify step output files.
    :param samples_files: A list of tuples - (files-key (in args_dict), real-file-name).

    :return: The reads count after classify step
    """
    reads_amount = []
    for sample_file in samples_files:
        try:
            df = pd.read_csv(str(files_folder / sample_file))
            t_read_count = df.loc[:, 'read count t'].map(lambda x: float(x)).sum()
            m_read_count = df.loc[:, 'read count m'].map(lambda x: float(x)).sum()
            reads_amount.append((str(sample_file) + ' Treatment', t_read_count))
            reads_amount.append((str(sample_file) + ' Control', m_read_count))
        except Exception as e:
            logging.error(f'Failed to count reads in {sample_file} please validate file.', exc_info=False)
            # sys.exit()
            raise e
    return reads_amount


def count_experiments_reads_by_step(args: dict, step: str, start: bool = False) -> None:
    """
    Count the reads in each experiment (treatment and mock) files.
    The files are chosen by the step name.

    :param args: A dict of all steps internal arguments (as keys) and their values.
    :param step: The step name.
    :param start: Set to true if the function called before any step is performed, else, false.
    """
    logging.debug(f'calculating reads amount...')
    files_folder = args['curr_in_dir'] if args['curr_in_dir'] == "" else Path(args['curr_in_dir'])
    reads_count = []
    if step in [settings.umi.STEP_NAME, settings.experiment_libraries_detector.STEP_NAME, settings.experiment_traces_remover.STEP_NAME]:

        samples_files = [args['EXPERIMENTS']['TX']['R1'],
                         args['EXPERIMENTS']['TX']['R2'],
                         args['EXPERIMENTS']['CONTROL']['R1'],
                         args['EXPERIMENTS']['CONTROL']['R2']]

        if files_folder == "":
            reads_count = count_fastq_reads(args['EXPERIMENTS']['TX']['EXPERIMENT_FOLDER_PATH'], samples_files[:2])
            reads_count.extend(count_fastq_reads(args['EXPERIMENTS']['CONTROL']['EXPERIMENT_FOLDER_PATH'], samples_files[2:]))
        else:
            reads_count = count_fastq_reads(files_folder, samples_files)

    elif step in [settings.bwa.STEP_NAME]:
        samples_files = [args['sam1'], args['sam2']]
        reads_count = count_sam_bwa_reads(files_folder, samples_files)

    elif step in [settings.reads_uniter.STEP_NAME]:
        samples_files = [args['csv1'], args['csv2']]
        reads_count = count_iceberg_csv_reads(files_folder, samples_files)

    elif step in [settings.experiments_merge_manager.STEP_NAME, settings.icebergs_uniter.STEP_NAME]:
        samples_files = [args['tx_and_control_merged_icebergs']]
        reads_count = count_icebergs_merged_csv_reads(files_folder, samples_files)

    elif step in [settings.classify.STEP_NAME, settings.sites_profile_calculator.STEP_NAME, settings.guide_alignment.STEP_NAME]:
        samples_files = [args['csv_ca'], args['csv_sb'], args['csv_noise']]
        reads_count = count_icebergs_merged_csv_reads(args['OUTPUT_FOLDER_PATH'], samples_files)

    description = ('\n' + ('\t' * 9)).join(['{}: {} reads.'.format(file_name, reads_count)
                                            for (file_name, reads_count) in reads_count])
    if start:
        args['remaining_reads']['start'] = reads_count
        logging.info(settings.STARTING_READ_AMOUNT_TEMPLATE.format(step=step, description=description))
    else:
        args['remaining_reads'][step] = reads_count
        logging.info(settings.READ_AMOUNT_TEMPLATE.format(step=step, description=description))
